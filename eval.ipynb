{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from dataset import PlacesDataset\n",
    "from data_dicts import Dicts\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam,SGD\n",
    "from sklearn.metrics import jaccard_similarity_score as jss\n",
    "from skimage.segmentation import find_boundaries as fb\n",
    "from unet_model import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic=Dicts()\n",
    "train_files,val_files=dic.get_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=PlacesDataset(train_files,augment=10,normalize_augment=False, transforms=True)\n",
    "test_dataset=PlacesDataset(val_files,augment=10,transforms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "unet=Unet()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)\n",
    "unet=unet.to(device)\n",
    "optimizer=Adam(unet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss_function(output_model,target):\n",
    "    n,c,h,w=output_model.size()\n",
    "    nt,ht,wt=target.size()\n",
    "    \n",
    "    if (h!=ht and w!=wt):\n",
    "        output_model=F.interpolate(output_model, size=(ht, wt), mode=\"bilinear\", align_corners=True)\n",
    "        \n",
    "    output_model=F.softmax(output_model.squeeze(0),dim=0).transpose(0,1).transpose(1,2)\n",
    "    predicted=np.zeros((ht,wt))\n",
    "    target=target.squeeze(0).cpu().numpy().reshape(-1)\n",
    "    output_model=output_model.cpu().numpy()\n",
    "    predicted=np.argmax(output_model,axis=2)\n",
    "    predicted=predicted.reshape(-1)\n",
    "    #predicted[predicted==19]=250\n",
    "    score=jss(target,predicted)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_IoU(input_image,target_image):\n",
    "    with torch.no_grad():\n",
    "        output_image=unet(input_image)\n",
    "        loss=test_loss_function(output_image,target_image)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (conv1a): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv1b): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2a): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv2b): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3a): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv3b): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4a): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv4b): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5a): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv5b): Sequential(\n",
       "    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (up1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv6a): Sequential(\n",
       "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv6b): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (up2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv7a): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv7b): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (up3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv8a): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv8b): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (up4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv9a): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv9b): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv9_final): Conv2d(64, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('model.pth')\n",
    "unet.load_state_dict(checkpoint['model_state_dict'])\n",
    "batch = checkpoint['epoch']\n",
    "tl = checkpoint['tl']\n",
    "vl = checkpoint['vl']\n",
    "unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8150485305786133\n"
     ]
    }
   ],
   "source": [
    "loss_test=0\n",
    "for j,inputs in enumerate(test_loader):\n",
    "    input_image=(inputs[0]).to(device)\n",
    "    target_image=(inputs[1]).to(device)\n",
    "    loss_test+=test_IoU(input_image,target_image)\n",
    "loss_test=loss_test/(j+1)\n",
    "print (loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,inputs in enumerate(test_loader):\n",
    "    input_image=(inputs[0]).to(device)\n",
    "    target=(inputs[1]).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_model=unet(input_image)\n",
    "        n,c,h,w=output_model.size()\n",
    "        n,ht,wt=target.size()\n",
    "\n",
    "        if (h!=ht and w!=wt):\n",
    "            output_model=F.interpolate(output_model, size=(ht, wt), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        output_model=F.softmax(output_model.squeeze(0),dim=0).transpose(0,1).transpose(1,2)\n",
    "        #print(output_model.size())\n",
    "        output_model=output_model.cpu().numpy()\n",
    "        #print(output_model.shape)\n",
    "        predicted=np.argmax(output_model,axis=2)\n",
    "    plt.imshow(train_dataset.decode_segmap(predicted), cmap='gray')\n",
    "    plt.imshow(input_image.squeeze(0).cpu().numpy().transpose(1,2,0)[:,:,::-1], cmap='jet', alpha=0.5)\n",
    "    plt.savefig('test_images/predicted/{}.png'.format(j+1))\n",
    "    plt.imshow(input_image.squeeze(0).cpu().numpy().transpose(1,2,0)[:,:,::-1])\n",
    "    plt.savefig('test_images/actual/{}.png'.format(j+1))\n",
    "    plt.imshow(train_dataset.decode_segmap(target.squeeze(0).cpu().numpy()), cmap='gray')\n",
    "    plt.imshow(input_image.squeeze(0).cpu().numpy().transpose(1,2,0)[:,:,::-1], cmap='jet', alpha=0.5)\n",
    "    plt.savefig('test_images/target/{}.png'.format(j+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
